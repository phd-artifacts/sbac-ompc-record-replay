{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default locations if parameter not passed\n",
    "benchmark_data_path = \"tb-compare-coaraci.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from rich import print as rprint\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import bootstrap\n",
    "\n",
    "benchmark_data = pickle.load(open(benchmark_data_path, \"rb\"))\n",
    "\n",
    "df = pd.DataFrame(benchmark_data[\"dataframe\"])\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_names = df[\"name\"].unique()\n",
    "print(f\"Benchmarks found: {bench_names}\")\n",
    "run_metadata = benchmark_data[\"config\"].applications\n",
    "n_runs = benchmark_data[\"config\"].metadata.runs\n",
    "\n",
    "df_bar = df[df[\"name\"] == 'tb-compare']\n",
    "\n",
    "\n",
    "n_runs = benchmark_data[\"config\"].metadata.runs\n",
    "print(f\"Number of runs: {n_runs}\")\n",
    "print(df_bar.columns)\n",
    "print(df_bar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_to_csv = False\n",
    "\n",
    "if dump_to_csv:\n",
    "    csv_path = os.path.join(os.path.dirname(benchmark_data_path), \"tb-compare.csv\")\n",
    "    print(f\"Dumping to {csv_path}\")\n",
    "    df_bar.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tb_time field (seconds)\n",
    "# get total time from the output\n",
    "def extract_elapsed_time(text):\n",
    "    matches = re.findall(r\"Elapsed Time ([\\d.eE+-]+) seconds\", text)\n",
    "    if matches:\n",
    "        # gets last mach\n",
    "        # float() already handles scientific notation\n",
    "        return float(matches[-1])\n",
    "    return float('nan')\n",
    "\n",
    "def extract_total_sched_time(text):\n",
    "    # Find all \"Scheduling : <number>\"\n",
    "    matches = re.findall(r\"Scheduling\\s*:\\s*(\\d+)\", text)\n",
    "    if not matches:\n",
    "        print(\"No scheduling time found in the text:\")\n",
    "        print(text)\n",
    "        return None\n",
    "    total_microseconds = sum(int(m) for m in matches)\n",
    "    return total_microseconds / 1e6  # microseconds to seconds\n",
    "\n",
    "def map_schedueler_name(image_name):\n",
    "    if \"improv\" in image_name:\n",
    "        return \"Record Replay\"\n",
    "    return \"Baseline\"\n",
    "\n",
    "def map_scheduler(row):\n",
    "    if 'improv' in row['image'].lower():\n",
    "        return 'Record Replay'\n",
    "    if row['scheduler'] == 'roundrobin':\n",
    "        return 'Baseline-RR'\n",
    "    if row['scheduler'] == 'heft':\n",
    "        return 'Baseline-HEFT'\n",
    "    return np.nan  # or 'Baseline-Unknown'\n",
    "\n",
    "df_bar['tb_time'] = df_bar['full_output'].apply(extract_elapsed_time)\n",
    "df_bar['sched_time'] = df_bar['full_output'].apply(extract_total_sched_time)\n",
    "# worker nodes is node_count - 1\n",
    "df_bar['worker_nodes'] = df_bar['node_count'].apply(lambda x: int(x - 1) if x > 1 else None)\n",
    "# df_bench['scheduler_name'] = df_bench['image'].apply(map_schedueler_name)\n",
    "df_bar['scheduler_name'] = df_bar.apply(map_scheduler, axis=1)\n",
    "\n",
    "print(df_bar.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "freeze, for now:\n",
    "kernel: compute_bound\n",
    "type: fft\n",
    "\n",
    "freeze:\n",
    "ompc_tb_iter_num: 100\n",
    "ompc_init_iter: 5\n",
    "ompc_resch_iter: 0\n",
    "\n",
    "y axsis: tb_time\n",
    "x axis: worker node count \n",
    "\n",
    "one line per iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for iter in df_bar['iter'].unique():\n",
    "  print(f\"Processing iteration: {iter}\")\n",
    "  for type in df_bar['type'].unique():\n",
    "    print(f\"Processing type: {type}\")\n",
    "    ## TODO: keep doing this for kernel and ompc_tb_iter_num\n",
    "\n",
    "    # apply filter for this loop\n",
    "    df_plot = df_bar[(df_bar['iter'] == iter) & (df_bar['type'] == type)].copy()\n",
    "    df_plot = df_plot[['tb_time', 'worker_nodes', 'scheduler_name']].copy()\n",
    "    df_plot = df_plot.dropna() # worker nodes can be None if np = 1\n",
    "\n",
    "    # 2) draw the plot\n",
    "    plt.figure()\n",
    "    sns.lineplot(\n",
    "        data=df_plot,\n",
    "        x='worker_nodes',\n",
    "        y='tb_time',\n",
    "        hue='scheduler_name',\n",
    "        style='scheduler_name',\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "        errorbar='ci',\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Worker Nodes')\n",
    "    plt.ylabel('Elapsed time (s)')\n",
    "    plt.title(f'{type.upper()} Dependency, {iter} iters. Elapsed time per worker node.')\n",
    "    plt.xticks(sorted(df_plot['worker_nodes'].unique()))\n",
    "    plt.legend(title='Scheduler')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "\n",
    "Show two stacked bars per worker node count.\n",
    "First stacked bar is: 'Record Replay' scheduler total scheduling stacked over interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def extract_interpolation_time(text):\n",
    "  # matchs all interpolation time and return sum of float\n",
    "  matches = re.findall(r\"Interpolation : ([\\d.eE+-]+)\", text)\n",
    "\n",
    "  if matches:\n",
    "    # Convert all matches to float and sum them up\n",
    "    total_time = sum(float(match) for match in matches)\n",
    "    return total_time / 1e6  # Convert microseconds to seconds\n",
    "  return float('nan')\n",
    "\n",
    "# 1) Prepare the data: only Record Replay has interpolation\n",
    "df_bar = df_bar.copy()\n",
    "df_bar['interp_time'] = 0.0\n",
    "mask_rr = df_bar['scheduler_name'] == 'Record Replay'\n",
    "df_bar.loc[mask_rr, 'interp_time'] = df_bar['full_output'].apply(extract_interpolation_time)\n",
    "\n",
    "df_bar = df_bar[['worker_nodes', 'scheduler_name', 'sched_time', 'interp_time']].copy()\n",
    "# drop if NaN in worker_nodes\n",
    "df_bar = df_bar.dropna(subset=['worker_nodes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scheduler_order = ['Record Replay', 'Baseline-HEFT', 'Baseline-RR']\n",
    "\n",
    "# 6 colors: [RR_sched, RR_interp, HEFT_sched, HEFT_interp, RRr_sched, RRr_interp]\n",
    "colors = sns.color_palette(\"colorblind\", len(scheduler_order) * 2)\n",
    "\n",
    "# bar width so total group width â‰ˆ 0.8\n",
    "n_sched = len(scheduler_order)\n",
    "width = 0.8 / n_sched\n",
    "\n",
    "# filter original df_bench, not df_bar\n",
    "df_loop = df_bar.copy()\n",
    "\n",
    "# 1) Aggregate means\n",
    "agg = (\n",
    "    df_loop\n",
    "    .groupby(['worker_nodes', 'scheduler_name'])[['sched_time', 'interp_time']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 2) Pivot for stacking\n",
    "sched = (\n",
    "    agg\n",
    "    .pivot(index='worker_nodes', columns='scheduler_name', values='sched_time')\n",
    "    [scheduler_order]\n",
    ")\n",
    "interp = (\n",
    "    agg\n",
    "    .pivot(index='worker_nodes', columns='scheduler_name', values='interp_time')\n",
    "    .fillna(0)[scheduler_order]\n",
    ")\n",
    "\n",
    "# 3) Plot\n",
    "nodes = sched.index.values\n",
    "x = np.arange(len(nodes))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for i, name in enumerate(scheduler_order):\n",
    "    # center the three bars at each x\n",
    "    offset = (i - (n_sched - 1) / 2) * width\n",
    "    pos = x + offset\n",
    "\n",
    "    # scheduling segment\n",
    "    ax.bar(\n",
    "        pos,\n",
    "        sched[name],\n",
    "        width,\n",
    "        label=f'{name} â€“ Scheduling',\n",
    "        color=colors[2*i]\n",
    "    )\n",
    "    # interpolation segment on top\n",
    "    ax.bar(\n",
    "        pos,\n",
    "        interp[name],\n",
    "        width,\n",
    "        bottom=sched[name],\n",
    "        label=f'{name} â€“ Interpolation',\n",
    "        color=colors[2*i + 1]\n",
    "    )\n",
    "\n",
    "# formatting\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(nodes)\n",
    "ax.set_xlabel(\"Worker Nodes\")\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_title(f\"FFT Dependency â€“ Iter = {iter_val}, Type = {type_val}\")\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
